<!DOCTYPE html>
<html lang="es">

<head>
  <meta charset="UTF-8">
  <!-- Meta para dispositivos m√≥viles (responsive) -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="shortcut icon" href="img/ico-cm.png" type="image/x-icon">
  <title>Inferencia Bayesiana segunda entrega</title>
  <!-- Vinculamos el archivo CSS -->
  <link rel="stylesheet" href="css/index.css">
</head>

<body>

  <!-- Datos de la Actividad -->
  <div class="datos-actividad">
    <p><strong>Asignatura:</strong> Inferencia bayesiana. Tercera entrega</p>
    <p><strong>Docente:</strong> Diana Herrero Coronel</p>
    <p><strong>Alumno:</strong> Steven Allus, Antonio L√≥pez Garc√≠a</p>
    <p><strong>Universidad:</strong> Carlemany Bachelor de Ciencia de Datos</p>
  </div>
  <a class="download" href="actividad_03_steven_antonio.ipynb" download="actividad_03_steven_antonio.ipynb">Download
    ipynb </a>


  <!-- Contenedor del √≠ndice -->
  <div class="indice">
    <h2>√çndice</h2>
    <button class="btn-toggle" onclick="toggleIndice()">
      Mostrar/Ocultar Ejercicios
    </button>

    <!-- Lista de las 20 preguntas -->
    <ul id="listaEjercicios">
      <li><a href="#respuesta_01">Actividad 1.</a></li>
      <li><a href="#respuesta_02">Actividad 2.</a></li>
      <li><a href="#respuesta_03">Actividad 3.</a></li>
      <li><a href="#respuesta_04">Actividad 4.</a></li>
      <li><a href="#respuesta_05">Actividad 5.</a></li>
    </ul>
  </div>

  <!-- =================== SECCIONES DE RESPUESTAS =================== -->

  <div id="respuesta_01" class="respuesta">
    <h3>Actividad 1</h3>
    <p>Un determinado medio de comunicaci√≥n desea llevar a cabo un estudio para saber cu√°l es el inter√©s que despierta
      entre sus lectores las noticias relacionadas directamente con conflictos b√©licos. Para ello contabilizar√° el
      n√∫mero de visitas en su canal de comunicaci√≥n online. El n√∫mero de visitas sigue una distribuci√≥n Poisson(ùúÉ).
    </p>
    <p>El estudio se realiz√≥ durante 10 meses y el n√∫mero medio de visitas mensuales fueron las siguientes: </p>
    <p>Se desea contrastar:</p>
    <p>320, 360,950, 400, 370, 75, 725, 120, 380, 375.</p>
    <p>ùêª0: ùúÉ=340</p>
    <p>ùêª1: ùúÉ = 450</p>
    <p>Previa no informativa ùëù(ùêª0) = ùëù(ùêª1) = 0‚Ä≤5.</p>

    <img src="img/ask_01.jpg">
    <img src="img/ask_01_01.jpg">
    <h2><strong>Conslusiones de nuestro resultado:</strong></h2>
    <ol>
      <li>
        <strong>Media muestral: 407.5</strong><br>
        La media de las observaciones (407.5) esta mas cerca del valor propuesto en H‚ÇÅ (Œ∏ = 450) que del valor en H‚ÇÄ (Œ∏
        = 340), lo que ya nos da una primera pista de que H‚ÇÅ podr√≠a tener mayor respaldo.
      </li>
      <li>
        <strong>Log Factor de Bayes (log B10): 42.23051</strong><br>
        El logaritmo del factor de Bayes es positivo y muy grande, indicando fuerte evidencia a favor de H1.
      </li>
      <li>
        <strong>Factor de Bayes (B10): 2.190146e+18</strong><br>
        Seg√∫n la escala de Kass y Raftery, cualquier valor mayor a 150 se considera evidencia "muy fuerte" a favor de la
        hip√≥tesis alternativa.<br>
        Este factor tan elevado indica que los datos observados son 2.19 quintillones de veces mas probables bajo la
        hip√≥tesis H‚ÇÅ que bajo H‚ÇÄ.
      </li>
      <li>
        <strong>Probabilidad a posteriori de H0: 4.565869e-19</strong><br>
        Esta probabilidad es pr√°cticamente cero.
      </li>
      <li>
        <strong>Probabilidad a posteriori de H1: 1</strong><br>
        Esto indica que, despu√©s de considerar los datos, la probabilidad de que H‚ÇÅ sea cierta es pr√°cticamente 1 (o
        100%).
      </li>
    </ol>

    <p><strong>Conclusi√≥n:</strong> Hay una evidencia abrumadora para rechazar H‚ÇÄ (Œ∏ = 340) y aceptar H‚ÇÅ (Œ∏ = 450). Los
      datos de visitas observados apoyan fuertemente la hip√≥tesis de que el par√°metro Œ∏ de la distribuci√≥n Poisson es
      450 y no 340.</p>

    <p>Este resultado es consistente con los datos observados, que incluyen valores altos como 950 y 725, los cuales son
      mas probables si Œ∏ = 450 que si Œ∏ = 340. La combinaci√≥n de todos los datos proporciona una evidencia estad√≠stica
      muy fuerte a favor de la hip√≥tesis alternativa.</p>


  </div>


  <div id="respuesta_02" class="respuesta">
    <h3>Actividad 2</h3>
    <p>Un grupo de expertos sobre el Cambio Clim√°tico investigan sobre el calentamiento global. Disponen de i = 1, ‚Ä¶ . ,
      20 observaciones que se distribuyen ùë¶ùëñ|ùúÉ~N(20, œÉ2). Los expertos est√°n interesados en realizar el siguiente
      test de hip√≥tesis y no disponen de informaci√≥n previa respecto a las hip√≥tesis:
    </p>
    <p>ùêª0: œÉ2 =1</p>
    <p>ùêª1 œÉ2 = 3</p>
    <p>Calcula el ùêµ10.</p>
    <p>BASE DE DATOS:</p>
    <p>20.20, 18.48, 18.93, 19.40, 18.12, 19.18, 19.99, 18.79, 21.56, 21.63,
      22.03, 19.38, 20.98, 19.44, 19.84, 19.87, 22.29, 21.43, 20.16, 22.16</p>
    <p><strong>C√≥gigo python</strong></p>
    <img src="img/ask_02.jpg">
  </div>

  <div id="respuesta_03" class="respuesta">
    <h3>Actividad 3</h3>
    <p>Calcular la Distribuci√≥n Predictiva Posterior del modelo Bernoulli-Beta (Binomial-Beta) para una observaci√≥n
      futura ùë¶‚àó = 0.
    </p>
    <p>NOTA: en clase hemos calculado la distribuci√≥n predictiva posterior para ùë¶‚àó = 1</p>
    <p>Si queremos cuantificar nuestro estado de informaci√≥n acerca de una observaci√≥n futura dado que ya tengo
      observaciones acerca de la realidad que estamos estudiando, deber√≠amos obtener la distribuci√≥n predictiva ya que
      tiene por objetivo describir el comportamiento estoc√°stico de una observaci√≥n que no tuve la oportunidad de
      observar, dado que ya observ√© una base de datos.</p>
      <p>¬øC√≥mo se escribe? y = y1, y2, ..., yn base de datos observados y* observaci√≥n futura</p>
      <p>yi siguen una Bernoulli con par√°metro p. Prior de ùëù:p ‚àºBeta(Œ±,Œ≤)</p>
      <p><strong>Distribuci√≥n posterior del par√°metro ùëù</strong></p>
    <img src="img/ask_03.jpg">
  </div>

  <div id="respuesta_04" class="respuesta">
    <h3>Actividad 4</h3>
    <p>Calcula la Distribuci√≥n Predictiva Posterior del Model Gamma-Poisson.
    </p>
    <p>Es importante justificar cada c√°lculo.</p>
    <p><strong>C√≥gigo python</strong></p>
    <img src="img/ask_04.jpg">
    <img src="img/ask_04_01.jpg">
    <img src="img/ask_04_02.jpg">
    <h2>Justificaci√≥n de los c√°lculos:</h2>

  <h3>1. Actualizaci√≥n de par√°metros:</h3>
  <ul>
    <li>Para una distribuci√≥n Gamma previa con par√°metros (Œ±, Œ≤) y datos Poisson, la distribuci√≥n posterior es Gamma con par√°metros:
      <ul>
        <li>Œ±_post = Œ±_prior + Œ£y (suma de todas las observaciones)</li>
        <li>Œ≤_post = Œ≤_prior + n (n√∫mero de observaciones)</li>
      </ul>
    </li>
    <li>Esta actualizaci√≥n representa la combinaci√≥n de la informaci√≥n previa con la informaci√≥n de los datos.</li>
  </ul>

  <h3>2. Distribuci√≥n predictiva posterior:</h3>
  <ul>
    <li>Cuando integramos la verosimilitud Poisson(y*|Œ∏) con la posterior Gamma(Œ∏|Œ±_post, Œ≤_post), obtenemos una distribuci√≥n Binomial Negativa.</li>
    <li>La f√≥rmula es: P(y|datos) = ‚à´ P(y|Œ∏) √ó P(Œ∏|datos) dŒ∏</li>
    <li>Esto resulta en una Binomial Negativa con par√°metros:
      <ul>
        <li>r = Œ±_post</li>
        <li>p = Œ≤_post / (Œ≤_post + 1)</li>
      </ul>
    </li>
  </ul>

  <h3>3. Propiedades de la predictiva posterior:</h3>
  <ul>
    <li>Media: Œ±_post / Œ≤_post (la misma que la media de la posterior de Œ∏)</li>
    <li>Varianza: Œ±_post(Œ≤_post + 1) / Œ≤_post¬≤ (mayor que la varianza de la posterior, reflejando la incertidumbre adicional de predecir un nuevo valor)</li>
  </ul>

  <p>Esta implementaci√≥n proporciona no solo las probabilidades para diferentes valores de y*, sino tambi√©n informaci√≥n sobre la distribuci√≥n predictiva posterior completa, lo que ayuda a entender mejor el comportamiento esperado de futuras observaciones.</p>

  </div>


  <div id="respuesta_05" class="respuesta">
    <h3>Actividad 5</h3>
    <p>Pregunta te√≥rica:
    </p>
    <p>Explica brevemente las principales diferencias entre las pruebas de hip√≥tesis bajo un enfoque frecuentista y uno
      bayesiano.</p>
    <p>Las pruebas de hip√≥tesis frecuentistas y bayesianas representan dos enfoques fundamentalmente distintos para
      evaluar evidencia estad√≠stica:</p>
    <h2>Diferencias entre pruebas de hip√≥tesis frecuentistas y bayesianas</h2>
    <p>Las pruebas de hip√≥tesis frecuentistas y bayesianas representan dos enfoques fundamentalmente distintos para
      evaluar evidencia estad√≠stica:</p>

    <h3>Enfoque frecuentista</h3>
    <ol>
      <li><strong>Interpretaci√≥n de probabilidad:</strong> Se basa en la frecuencia relativa a largo plazo de eventos en
        experimentos repetidos.</li>
      <li><strong>Hip√≥tesis fijas, datos aleatorios:</strong> Considera los par√°metros como valores fijos desconocidos,
        y los datos como aleatorios.</li>
      <li><strong>Valor p:</strong> Calcula la probabilidad de obtener datos tan o m√°s extremos que los observados,
        asumiendo que la hip√≥tesis nula es cierta: P(datos|H‚ÇÄ).</li>
      <li><strong>Decisi√≥n binaria:</strong> T√≠picamente resulta en rechazar o no rechazar la hip√≥tesis nula bas√°ndose
        en un umbral predefinido (p &lt; 0.05).</li>
      <li><strong>Informaci√≥n previa:</strong> No incorpora formalmente conocimiento previo o creencias sobre los
        par√°metros.</li>
    </ol>

    <h3>Enfoque bayesiano</h3>
    <ol>
      <li><strong>Interpretaci√≥n de probabilidad:</strong> Representa el grado de creencia o estado de conocimiento
        sobre una hip√≥tesis.</li>
      <li><strong>Datos fijos, hip√≥tesis aleatorias:</strong> Una vez observados los datos, calcula probabilidades sobre
        las hip√≥tesis.</li>
      <li><strong>Probabilidad posterior:</strong> Calcula directamente la probabilidad de la hip√≥tesis dados los datos:
        P(H | datos).</li>
      <li><strong>Medici√≥n de evidencia:</strong> Utiliza factores de Bayes o probabilidades posteriores para
        cuantificar la evidencia relativa entre hip√≥tesis.</li>
      <li><strong>Informaci√≥n previa:</strong> Incorpora expl√≠citamente el conocimiento o creencias previas a trav√©s de
        distribuciones a priori.</li>
    </ol>

    <h3>Diferencias clave</h3>
    <ul>
      <li>El enfoque frecuentista responde ‚Äú¬øCu√°n probable son estos datos si la hip√≥tesis nula es cierta?‚Äù, mientras
        que el bayesiano responde ‚Äú¬øCu√°n probable es esta hip√≥tesis dados los datos observados?‚Äù</li>
      <li>El bayesiano permite actualizar continuamente el conocimiento a medida que llegan nuevos datos, mientras que
        el frecuentista trata cada prueba como un evento independiente.</li>
      <li>El enfoque bayesiano cuantifica directamente la incertidumbre sobre los par√°metros y eval√∫a hip√≥tesis de
        manera probabil√≠stica, en lugar de ofrecer decisiones binarias.</li>
      <li>Los m√©todos bayesianos integran informaci√≥n previa, lo que puede ser una ventaja cuando hay conocimiento
        experto disponible, pero tambi√©n introduce subjetividad en la elecci√≥n de las distribuciones previas.</li>
    </ul>
  </div>


  <!-- =============================================================== -->

  <!-- Script -->
  <script src="js/index.js"></script>
</body>

</html>